# Snapshot Hyperspectral Imaging via Compressive Sensing and Implicit Neural Representation

This repository contains the implementation of our method for **snapshot hyperspectral image reconstruction** using **implicit neural representations**, presented in:

> **J. Boondicharern, A. R. Vazifeh, and J. W. Fleischer**,  
> *Snapshot Hyperspectral Imaging via Compressive Sensing and Implicit Neural Representation,*  
> *Computational Optical Sensing and Imaging (COSI), Optica Imaging Congress 2025,*  
> [https://doi.org/10.1364/COSI.2025.CTu1B.5](https://doi.org/10.1364/COSI.2025.CTu1B.5)


---

## Overview

**Hyperspectral Imaging (HSI)** captures images across many narrow and contiguous spectral bands. Unlike RGB imaging, which captures only three color channels, HSI provides a rich spectral signature at every pixel, enabling powerful applications in **remote sensing**, **environmental monitoring**, **precision agriculture**, and **medical diagnostics**.

However, conventional HSI systems face a fundamental **trade-off between spatial, spectral, and temporal resolution**:

- **Spatial Scanning (push-broom systems):** captures one line of the scene at a time, requiring motion of the object or sensor.  
- **Spectral Scanning (filter-based systems):** sequentially captures one wavelength at a time, leading to long acquisition times and temporal misalignment.  
- **Snapshot Imaging:** captures all wavelengths in a single exposure using multiplexed optics or coded apertures, but produces **sparse, spectrally mixed measurements**.

The last category, **snapshot hyperspectral imaging**, offers high-speed acquisition but poses a major reconstruction challenge. Each pixel typically measures only one wavelength, making the recovery of the full 3D hyperspectral cube from a 2D snapshot an **ill-posed inverse problem**.  

---

## Method

In our approach, we address this challenge by combining with **implicit neural representations**, using a **sinusoidal activation function (SIREN)** to model the hyperspectral cube as a continuous function of spatialâ€“spectral coordinates. Each snapshot image is treated as a set of **sparse spectral observations**, where only a fraction of pixels correspond to each wavelength due to coded apertures or filter mosaics.   We model the true hyperspectral signal as a **continuous function**:

<p align="center">
  <strong>f<sub>Î¸</sub>(x, y; Î») â†’ I(x, y; Î»)</strong>
</p>

where (<em>x</em>, <em>y</em>; <em>Î»</em>) are spatialâ€“spectral coordinates, and <strong>f<sub>Î¸</sub></strong> is a <strong>SIREN network</strong> (sinusoidal MLP). The sinusoidal activation captures high-frequency spatial and spectral structures that ReLU-based networks miss, a limitation called spectral bias.

The model is trained to minimize a <strong>mean squared reconstruction loss</strong> between predicted intensities and the sparse coded measurements. Once optimized, <strong>f<sub>Î¸</sub></strong> becomes a <strong>fully continuous hyperspectral field</strong>, from which any wavelength or combination can be queried and visualized at arbitrary resolution.

This approach enables reconstruction of a complete hyperspectral cube from a single coded 2D measurement, performing both spectral interpolation and extrapolation without any external supervision or prior information.

<p align="center">
  <img src="Code/Method.png" alt="Method Overview" width="700">
  <br>
  <em>Figure 1: Overview of the proposed snapshot hyperspectral reconstruction framework using implicit neural representation.</em>
</p>

---

## ðŸŽ¥ Results

We tested our method on **four hyperspectral datasets**: **CS-hsdb**, **HS-SOD**, **Dermatology**, and **Pavia University**.  
Each dataset contains 10 spectral bands, resulting in hyperspectral cubes of dimension *(H, W, 10)*.

For each dataset, we masked **90% of the pixels** per spectral band and used **complementary aperture codes** across wavelengths.  
Our reconstruction network then recovered the full hyperspectral cube from these sparse coded measurements.  
Below are qualitative reconstruction results for one spectral band from each dataset.

<p align="center">
  <img src="Snapshot-Hyperspectral-Imaging-Neural-Field/Results/CS-hsdb/video/CS-hsdb.png" width="45%" alt="CS-hsdb result">
  <img src="Snapshot-Hyperspectral-Imaging-Neural-Field/Results/HS-SOD/video/HS-SOD.png" width="45%" alt="HS-SOD result"><br><br>
  <img src="Snapshot-Hyperspectral-Imaging-Neural-Field/Results/dermatology/video/dermatology.png" width="45%" alt="Dermatology result">
  <img src="Snapshot-Hyperspectral-Imaging-Neural-Field/Results/pavia_u/video/pavia_u.png" width="45%" alt="PaviaU result">
</p>

<p align="center">
  <em>Figure: Reconstruction results for a single spectral band from each dataset.  
  Each hyperspectral cube was reconstructed from only 10% of the observed pixels using complementary coded apertures.</em>
</p>

Videos showing full spectral reconstructions for each dataset can be downloaded here:

- ðŸŽ¬ [CS-hsdb Reconstruction Video](Snapshot-Hyperspectral-Imaging-Neural-Field/Results/CS-hsdb/video/CS-hsdb_jet.mp4)  
- ðŸŽ¬ [HS-SOD Reconstruction Video](Snapshot-Hyperspectral-Imaging-Neural-Field/Results/HS-SOD/video/HS-SOD_jet.mp4)  
- ðŸŽ¬ [Dermatology Reconstruction Video](Snapshot-Hyperspectral-Imaging-Neural-Field/Results/dermatology/video/dermatology_jet.mp4)  
- ðŸŽ¬ [Pavia University Reconstruction Video](Snapshot-Hyperspectral-Imaging-Neural-Field/Results/pavia_u/video/pavia_u_jet.mp4)

---

## Key Features

- âœ… **Single-shot reconstruction** from sparse coded measurements  
- âœ… **Fully unsupervised** optimization (no pretraining or priors)  
- âœ… **Sensor-agnostic design**, compatible with various aperture codes

---

## Citation

If you find this repository useful, please consider citing our paper:

```bibtex
@inproceedings{boondicharern2025snapshot,
  title     = {Snapshot Hyperspectral Imaging via Compressive Sensing and Implicit Neural Representation},
  author    = {Jatearoon Boondicharern and Amir Reza Vazifeh and Jason W. Fleischer},
  booktitle = {Computational Optical Sensing and Imaging (COSI), Optica Imaging Congress 2025},
  series    = {Technical Digest Series},
  publisher = {Optica Publishing Group},
  year      = {2025},
  paper     = {CTu1B.5},
  doi       = {10.1364/COSI.2025.CTu1B.5}
}
